{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, string\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.findall(r'\\b[a-z]+\\b', text)\n",
    "    return ' '.join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Insult</th>\n",
       "      <th>Date</th>\n",
       "      <th>Comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>20120618192155Z</td>\n",
       "      <td>\"You fuck your dad.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>20120528192215Z</td>\n",
       "      <td>\"i really don't understand your point.\\xa0 It ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\"A\\\\xc2\\\\xa0majority of Canadians can and has ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\"listen if you dont wanna get married to a man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>20120619094753Z</td>\n",
       "      <td>\"C\\xe1c b\\u1ea1n xu\\u1ed1ng \\u0111\\u01b0\\u1edd...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Insult             Date                                            Comment\n",
       "0       1  20120618192155Z                               \"You fuck your dad.\"\n",
       "1       0  20120528192215Z  \"i really don't understand your point.\\xa0 It ...\n",
       "2       0              NaN  \"A\\\\xc2\\\\xa0majority of Canadians can and has ...\n",
       "3       0              NaN  \"listen if you dont wanna get married to a man...\n",
       "4       0  20120619094753Z  \"C\\xe1c b\\u1ea1n xu\\u1ed1ng \\u0111\\u01b0\\u1edd..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data = pd.read_csv('./train.csv')\n",
    "training_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data['cleaned_comment'] = training_data['Comment'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Insult</th>\n",
       "      <th>Date</th>\n",
       "      <th>Comment</th>\n",
       "      <th>cleaned_comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>20120618192155Z</td>\n",
       "      <td>\"You fuck your dad.\"</td>\n",
       "      <td>you fuck your dad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>20120528192215Z</td>\n",
       "      <td>\"i really don't understand your point.\\xa0 It ...</td>\n",
       "      <td>i really don t understand your point it seems ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\"A\\\\xc2\\\\xa0majority of Canadians can and has ...</td>\n",
       "      <td>a of canadians can and has been wrong before n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\"listen if you dont wanna get married to a man...</td>\n",
       "      <td>listen if you dont wanna get married to a man ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>20120619094753Z</td>\n",
       "      <td>\"C\\xe1c b\\u1ea1n xu\\u1ed1ng \\u0111\\u01b0\\u1edd...</td>\n",
       "      <td>c b xu bi t xecnh c ho kh nc ng d ng cu xed ch...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Insult             Date                                            Comment  \\\n",
       "0       1  20120618192155Z                               \"You fuck your dad.\"   \n",
       "1       0  20120528192215Z  \"i really don't understand your point.\\xa0 It ...   \n",
       "2       0              NaN  \"A\\\\xc2\\\\xa0majority of Canadians can and has ...   \n",
       "3       0              NaN  \"listen if you dont wanna get married to a man...   \n",
       "4       0  20120619094753Z  \"C\\xe1c b\\u1ea1n xu\\u1ed1ng \\u0111\\u01b0\\u1edd...   \n",
       "\n",
       "                                     cleaned_comment  \n",
       "0                                  you fuck your dad  \n",
       "1  i really don t understand your point it seems ...  \n",
       "2  a of canadians can and has been wrong before n...  \n",
       "3  listen if you dont wanna get married to a man ...  \n",
       "4  c b xu bi t xecnh c ho kh nc ng d ng cu xed ch...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3947, 4)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2898\n",
       "1    1049\n",
       "Name: Insult, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data['Insult'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Insult</th>\n",
       "      <th>Date</th>\n",
       "      <th>Comment</th>\n",
       "      <th>cleaned_comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>20120618192155Z</td>\n",
       "      <td>\"You fuck your dad.\"</td>\n",
       "      <td>you fuck your dad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\"shut the fuck up. you and the rest of your fa...</td>\n",
       "      <td>shut the fuck up you and the rest of your fagg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>20120502173553Z</td>\n",
       "      <td>\"Either you are fake or extremely stupid...may...</td>\n",
       "      <td>either you are fake or extremely stupid maybe ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>20120620160512Z</td>\n",
       "      <td>\"That you are an idiot who understands neither...</td>\n",
       "      <td>that you are an idiot who understands neither ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>20120611090207Z</td>\n",
       "      <td>\"FOR SOME REASON U SOUND RETARDED. LOL. DAMN. ...</td>\n",
       "      <td>for some reason u sound retarded lol damn wher...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3929</th>\n",
       "      <td>1</td>\n",
       "      <td>20120619022522Z</td>\n",
       "      <td>\"Why don't you shut your stupid mouth, pennyla...</td>\n",
       "      <td>why don t you shut your stupid mouth pennylane...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3931</th>\n",
       "      <td>1</td>\n",
       "      <td>20120618222326Z</td>\n",
       "      <td>\"You goofy Repub thugs don't have a clue, not ...</td>\n",
       "      <td>you goofy repub thugs don t have a clue not th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3934</th>\n",
       "      <td>1</td>\n",
       "      <td>20120610083604Z</td>\n",
       "      <td>\"True, maybe he's deliberately being an assh*l...</td>\n",
       "      <td>true maybe he s deliberately being an assh le ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3935</th>\n",
       "      <td>1</td>\n",
       "      <td>20120515160649Z</td>\n",
       "      <td>\"JoelWeltman, you look like a pedophile from y...</td>\n",
       "      <td>joelweltman you look like a pedophile from you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3942</th>\n",
       "      <td>1</td>\n",
       "      <td>20120502172717Z</td>\n",
       "      <td>\"you are both morons and that is never happening\"</td>\n",
       "      <td>you are both morons and that is never happening</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1049 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Insult             Date  \\\n",
       "0          1  20120618192155Z   \n",
       "7          1              NaN   \n",
       "8          1  20120502173553Z   \n",
       "9          1  20120620160512Z   \n",
       "15         1  20120611090207Z   \n",
       "...      ...              ...   \n",
       "3929       1  20120619022522Z   \n",
       "3931       1  20120618222326Z   \n",
       "3934       1  20120610083604Z   \n",
       "3935       1  20120515160649Z   \n",
       "3942       1  20120502172717Z   \n",
       "\n",
       "                                                Comment  \\\n",
       "0                                  \"You fuck your dad.\"   \n",
       "7     \"shut the fuck up. you and the rest of your fa...   \n",
       "8     \"Either you are fake or extremely stupid...may...   \n",
       "9     \"That you are an idiot who understands neither...   \n",
       "15    \"FOR SOME REASON U SOUND RETARDED. LOL. DAMN. ...   \n",
       "...                                                 ...   \n",
       "3929  \"Why don't you shut your stupid mouth, pennyla...   \n",
       "3931  \"You goofy Repub thugs don't have a clue, not ...   \n",
       "3934  \"True, maybe he's deliberately being an assh*l...   \n",
       "3935  \"JoelWeltman, you look like a pedophile from y...   \n",
       "3942  \"you are both morons and that is never happening\"   \n",
       "\n",
       "                                        cleaned_comment  \n",
       "0                                     you fuck your dad  \n",
       "7     shut the fuck up you and the rest of your fagg...  \n",
       "8     either you are fake or extremely stupid maybe ...  \n",
       "9     that you are an idiot who understands neither ...  \n",
       "15    for some reason u sound retarded lol damn wher...  \n",
       "...                                                 ...  \n",
       "3929  why don t you shut your stupid mouth pennylane...  \n",
       "3931  you goofy repub thugs don t have a clue not th...  \n",
       "3934  true maybe he s deliberately being an assh le ...  \n",
       "3935  joelweltman you look like a pedophile from you...  \n",
       "3942    you are both morons and that is never happening  \n",
       "\n",
       "[1049 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How does it look the insults\n",
    "training_data.query('Insult == 1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make some features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Formulate the problem into mathematical terms. The function `CountVectorizer` transform all the words of each tweet into a vector. The lenght of this vector is equal to the total number of unique representative words in the dataset. The function finaly returns a matrix with all these vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(max_features=5000, ngram_range=(1, 3), stop_words='english')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vectorizer = CountVectorizer(analyzer='word', ngram_range=(1,3), stop_words='english', max_features=5000)\n",
    "count_vectorizer.fit(training_data['cleaned_comment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#count_vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Featurizing tags\n",
    "X = count_vectorizer.transform(training_data['cleaned_comment'])\n",
    "y = training_data['Insult']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "CountVectorizer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3947x5000 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 45934 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compress representation of the matrix\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-validate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the data is going to be divided in train data and test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data (X, y, p=0.75):\n",
    "    \"\"\" \n",
    "    X = Feature matrix\n",
    "    y = vector\n",
    "    p = percentage of data in training data\n",
    "    \"\"\"\n",
    "    mask = np.array([ bool(np.random.binomial(1,p)) for _ in range(X.shape[0])])\n",
    "    X_train = X[mask]\n",
    "    y_train = y[mask]\n",
    "    X_test = X[~mask]\n",
    "    y_test = y[~mask]\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    0.811249\n",
       "True     0.188751\n",
       "dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Explanation of previus code\n",
    "p = 0.2\n",
    "mask = np.array([ bool(np.random.binomial(1,p)) for _ in range(X.shape[0])])\n",
    "pd.Series(mask).value_counts() / X.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = split_data(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit a model on training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(verbose=1)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Classifier ~ Classifier\n",
    "clf = LogisticRegression(verbose=1)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate model on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score:  0.8352570828961176\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "predictions = clf.predict(X_test)\n",
    "validation_score = accuracy_score(y_test, predictions)\n",
    "print('Validation score: ', validation_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remeber, everything is a hyper-parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is important to automatize the process of testing models and hyperparameters, in that way you can look faster which model works fine and focus in it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PredictionPipeline:\n",
    "    \n",
    "    def __init__(self, ngram_range, vectorizer_class, model_class, training_data):\n",
    "        self.ngram_range = ngram_range\n",
    "        self.vectorizer_class = vectorizer_class\n",
    "        self.model_class = model_class\n",
    "        self.training_data = training_data\n",
    "        self.vectorizer = None\n",
    "        self.X = None\n",
    "        self.y = None\n",
    "        self.model = None\n",
    "        self.validation_score = None\n",
    "        \n",
    "    def run(self):\n",
    "        self._fit_vectorizer()\n",
    "        self._featurize_text()\n",
    "        self._split_train_and_validation_sets()\n",
    "        self._fit_model_on_training_data()\n",
    "        self._validate_model_on_validation_set()\n",
    "        \n",
    "        print(\n",
    "        \"\"\"\n",
    "        Vectorizer Class: {vectorizer_class}\\n\n",
    "        N-gram Range: {ngram_range}\\n\n",
    "        Model Class: {model_class}\\n\n",
    "        Validation Score: {validation_score}\n",
    "            \n",
    "        \"\"\".format(\n",
    "\n",
    "            vectorizer_class=repr(self.vectorizer_class.__name__), \n",
    "            ngram_range=self.ngram_range, \n",
    "            model_class=repr(self.model_class.__name__), \n",
    "            validation_score=round(self.validation_score, 4)\n",
    "\n",
    "                )\n",
    "            )\n",
    "        \n",
    "        \n",
    "    def _fit_vectorizer(self):\n",
    "        self.vectorizer = vectorizer_class(analyzer='word', ngram_range=ngram_range,\n",
    "                                           stop_words='english', max_features=50000)\n",
    "        self.vectorizer.fit(self.training_data['cleaned_comment'])\n",
    "       \n",
    "    \n",
    "    def _featurize_text(self):\n",
    "        self.X = self.vectorizer.transform(self.training_data['cleaned_comment'])\n",
    "        self.y = self.training_data['Insult']\n",
    "        \n",
    "    \n",
    "    def _split_train_and_validation_sets(self):\n",
    "        self.X_train, self.X_validation, self.y_train, self.y_validation = train_test_split(\n",
    "        self.X, self.y, test_size=0.25, random_state=123)\n",
    "       \n",
    "    \n",
    "    def _fit_model_on_training_data(self):\n",
    "        self.model = self.model_class()\n",
    "        self.model.fit(self.X_train, self.y_train)\n",
    "        \n",
    "    def _validate_model_on_validation_set(self):\n",
    "        predictions = self.model.predict(self.X_validation)\n",
    "        self.validation_score = accuracy_score(self.y_validation, predictions)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        Vectorizer Class: 'CountVectorizer'\n",
      "\n",
      "        N-gram Range: (1, 1)\n",
      "\n",
      "        Model Class: 'LogisticRegression'\n",
      "\n",
      "        Validation Score: 0.8227\n",
      "            \n",
      "        \n",
      "\n",
      "        Vectorizer Class: 'CountVectorizer'\n",
      "\n",
      "        N-gram Range: (1, 1)\n",
      "\n",
      "        Model Class: 'LinearSVC'\n",
      "\n",
      "        Validation Score: 0.8166\n",
      "            \n",
      "        \n",
      "\n",
      "        Vectorizer Class: 'CountVectorizer'\n",
      "\n",
      "        N-gram Range: (1, 1)\n",
      "\n",
      "        Model Class: 'RandomForestClassifier'\n",
      "\n",
      "        Validation Score: 0.8318\n",
      "            \n",
      "        \n",
      "\n",
      "        Vectorizer Class: 'TfidfVectorizer'\n",
      "\n",
      "        N-gram Range: (1, 1)\n",
      "\n",
      "        Model Class: 'LogisticRegression'\n",
      "\n",
      "        Validation Score: 0.7923\n",
      "            \n",
      "        \n",
      "\n",
      "        Vectorizer Class: 'TfidfVectorizer'\n",
      "\n",
      "        N-gram Range: (1, 1)\n",
      "\n",
      "        Model Class: 'LinearSVC'\n",
      "\n",
      "        Validation Score: 0.8278\n",
      "            \n",
      "        \n",
      "\n",
      "        Vectorizer Class: 'TfidfVectorizer'\n",
      "\n",
      "        N-gram Range: (1, 1)\n",
      "\n",
      "        Model Class: 'RandomForestClassifier'\n",
      "\n",
      "        Validation Score: 0.8217\n",
      "            \n",
      "        \n",
      "\n",
      "        Vectorizer Class: 'CountVectorizer'\n",
      "\n",
      "        N-gram Range: (1, 2)\n",
      "\n",
      "        Model Class: 'LogisticRegression'\n",
      "\n",
      "        Validation Score: 0.8257\n",
      "            \n",
      "        \n",
      "\n",
      "        Vectorizer Class: 'CountVectorizer'\n",
      "\n",
      "        N-gram Range: (1, 2)\n",
      "\n",
      "        Model Class: 'LinearSVC'\n",
      "\n",
      "        Validation Score: 0.8257\n",
      "            \n",
      "        \n",
      "\n",
      "        Vectorizer Class: 'CountVectorizer'\n",
      "\n",
      "        N-gram Range: (1, 2)\n",
      "\n",
      "        Model Class: 'RandomForestClassifier'\n",
      "\n",
      "        Validation Score: 0.8166\n",
      "            \n",
      "        \n",
      "\n",
      "        Vectorizer Class: 'TfidfVectorizer'\n",
      "\n",
      "        N-gram Range: (1, 2)\n",
      "\n",
      "        Model Class: 'LogisticRegression'\n",
      "\n",
      "        Validation Score: 0.7568\n",
      "            \n",
      "        \n",
      "\n",
      "        Vectorizer Class: 'TfidfVectorizer'\n",
      "\n",
      "        N-gram Range: (1, 2)\n",
      "\n",
      "        Model Class: 'LinearSVC'\n",
      "\n",
      "        Validation Score: 0.8055\n",
      "            \n",
      "        \n",
      "\n",
      "        Vectorizer Class: 'TfidfVectorizer'\n",
      "\n",
      "        N-gram Range: (1, 2)\n",
      "\n",
      "        Model Class: 'RandomForestClassifier'\n",
      "\n",
      "        Validation Score: 0.8004\n",
      "            \n",
      "        \n",
      "\n",
      "        Vectorizer Class: 'CountVectorizer'\n",
      "\n",
      "        N-gram Range: (1, 3)\n",
      "\n",
      "        Model Class: 'LogisticRegression'\n",
      "\n",
      "        Validation Score: 0.8237\n",
      "            \n",
      "        \n",
      "\n",
      "        Vectorizer Class: 'CountVectorizer'\n",
      "\n",
      "        N-gram Range: (1, 3)\n",
      "\n",
      "        Model Class: 'LinearSVC'\n",
      "\n",
      "        Validation Score: 0.8146\n",
      "            \n",
      "        \n",
      "\n",
      "        Vectorizer Class: 'CountVectorizer'\n",
      "\n",
      "        N-gram Range: (1, 3)\n",
      "\n",
      "        Model Class: 'RandomForestClassifier'\n",
      "\n",
      "        Validation Score: 0.8146\n",
      "            \n",
      "        \n",
      "\n",
      "        Vectorizer Class: 'TfidfVectorizer'\n",
      "\n",
      "        N-gram Range: (1, 3)\n",
      "\n",
      "        Model Class: 'LogisticRegression'\n",
      "\n",
      "        Validation Score: 0.7568\n",
      "            \n",
      "        \n",
      "\n",
      "        Vectorizer Class: 'TfidfVectorizer'\n",
      "\n",
      "        N-gram Range: (1, 3)\n",
      "\n",
      "        Model Class: 'LinearSVC'\n",
      "\n",
      "        Validation Score: 0.8126\n",
      "            \n",
      "        \n",
      "\n",
      "        Vectorizer Class: 'TfidfVectorizer'\n",
      "\n",
      "        N-gram Range: (1, 3)\n",
      "\n",
      "        Model Class: 'RandomForestClassifier'\n",
      "\n",
      "        Validation Score: 0.8085\n",
      "            \n",
      "        \n",
      "\n",
      "        Vectorizer Class: 'CountVectorizer'\n",
      "\n",
      "        N-gram Range: (1, 4)\n",
      "\n",
      "        Model Class: 'LogisticRegression'\n",
      "\n",
      "        Validation Score: 0.8308\n",
      "            \n",
      "        \n",
      "\n",
      "        Vectorizer Class: 'CountVectorizer'\n",
      "\n",
      "        N-gram Range: (1, 4)\n",
      "\n",
      "        Model Class: 'LinearSVC'\n",
      "\n",
      "        Validation Score: 0.8146\n",
      "            \n",
      "        \n",
      "\n",
      "        Vectorizer Class: 'CountVectorizer'\n",
      "\n",
      "        N-gram Range: (1, 4)\n",
      "\n",
      "        Model Class: 'RandomForestClassifier'\n",
      "\n",
      "        Validation Score: 0.8197\n",
      "            \n",
      "        \n",
      "\n",
      "        Vectorizer Class: 'TfidfVectorizer'\n",
      "\n",
      "        N-gram Range: (1, 4)\n",
      "\n",
      "        Model Class: 'LogisticRegression'\n",
      "\n",
      "        Validation Score: 0.7619\n",
      "            \n",
      "        \n",
      "\n",
      "        Vectorizer Class: 'TfidfVectorizer'\n",
      "\n",
      "        N-gram Range: (1, 4)\n",
      "\n",
      "        Model Class: 'LinearSVC'\n",
      "\n",
      "        Validation Score: 0.8197\n",
      "            \n",
      "        \n",
      "\n",
      "        Vectorizer Class: 'TfidfVectorizer'\n",
      "\n",
      "        N-gram Range: (1, 4)\n",
      "\n",
      "        Model Class: 'RandomForestClassifier'\n",
      "\n",
      "        Validation Score: 0.8004\n",
      "            \n",
      "        \n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "\n",
    "for ngram_range in [(1,1), (1,2), (1,3), (1,4)]:\n",
    "    for vectorizer_class in [CountVectorizer, TfidfVectorizer]:\n",
    "        for model_class in [LogisticRegression, LinearSVC, RandomForestClassifier]:\n",
    "            \n",
    "            # Run prediction pipeline\n",
    "            prediction_pipeline = PredictionPipeline(\n",
    "                ngram_range = ngram_range,\n",
    "                vectorizer_class = vectorizer_class,\n",
    "                model_class = model_class,\n",
    "                training_data =  training_data\n",
    "            )\n",
    "            prediction_pipeline.run()\n",
    "            \n",
    "            results[str(prediction_pipeline.validation_score)] = {\n",
    "                'vectorizer_class': prediction_pipeline.vectorizer_class,\n",
    "                'ngram_range': prediction_pipeline.ngram_range,\n",
    "                'model_class': prediction_pipeline.model_class\n",
    "            }\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.8318135764944276\n",
      "Parameters: {'vectorizer_class': <class 'sklearn.feature_extraction.text.CountVectorizer'>, 'ngram_range': (1, 1), 'model_class': <class 'sklearn.ensemble._forest.RandomForestClassifier'>}\n",
      "Score: 0.8308004052684904\n",
      "Parameters: {'vectorizer_class': <class 'sklearn.feature_extraction.text.CountVectorizer'>, 'ngram_range': (1, 4), 'model_class': <class 'sklearn.linear_model._logistic.LogisticRegression'>}\n",
      "Score: 0.8277608915906788\n",
      "Parameters: {'vectorizer_class': <class 'sklearn.feature_extraction.text.TfidfVectorizer'>, 'ngram_range': (1, 1), 'model_class': <class 'sklearn.svm._classes.LinearSVC'>}\n"
     ]
    }
   ],
   "source": [
    "top_3_scores = sorted(results.keys(), reverse=True)[:3]\n",
    "\n",
    "for score in top_3_scores:\n",
    "    print(f'Score: {score}\\nParameters: {results[score]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0.8318135764944276', '0.8308004052684904', '0.8277608915906788']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_3_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_score_key = top_3_scores[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(max_features=50000, stop_words='english')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer_class = results[top_score_key]['vectorizer_class']\n",
    "ngram_range = results[top_score_key]['ngram_range']\n",
    "model_class = results[top_score_key]['model_class']\n",
    "\n",
    "# Fit vectorizer\n",
    "vectorizer = vectorizer_class(analyzer='word', ngram_range=ngram_range, stop_words='english', max_features=50000)\n",
    "vectorizer.fit(training_data['cleaned_comment']) #Generates the vector with all the vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform text\n",
    "X = vectorizer.transform(training_data['cleaned_comment'])\n",
    "y = training_data['Insult']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit model on training data\n",
    "model = model_class()\n",
    "model.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run it live"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please enter a string: you are a dumb\n",
      "Insult:  True\n"
     ]
    }
   ],
   "source": [
    "input_string = input('Please enter a string: ')\n",
    "input_string = clean_text(input_string)\n",
    "X_test = vectorizer.transform([input_string])\n",
    "\n",
    "prediction = model.predict(X_test)[0]\n",
    "\n",
    "print('Insult: ', bool(prediction))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
