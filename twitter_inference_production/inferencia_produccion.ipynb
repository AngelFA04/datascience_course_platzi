{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recopilar datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tweepy\n",
    "from tweepy import Stream"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cargar credenciales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONSUMER_KEY = os.getenv('TWITTER_CONSUMER_KEY')\n",
    "CONSUMER_SECRET = os.getenv('TWITTER_CONSUMER_SECRET')\n",
    "ACCESS_TOKEN = os.getenv('TWITTER_ACCES_TOKEN')\n",
    "ACCESS_TOKEN_SECRET = os.getenv('TWITTER_TOKEN_SECRET')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLOMBIA_GEO_LOCATION_BOUNDING_BOX = [-78.31, 0.44, -70.71, 11.39]\n",
    "NUMBER_OF_TWEETS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = tweepy.OAuthHandler(CONSUMER_KEY, CONSUMER_SECRET)\n",
    "auth.set_access_token(ACCESS_TOKEN, ACCESS_TOKEN_SECRET)\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unidecode import unidecode\n",
    "\n",
    "def make_lowercase(tweet):\n",
    "    return tweet.lower()\n",
    "\n",
    "def remove_diacritics(tweet):\n",
    "    return unidecode(tweet)\n",
    "\n",
    "def remove_non_alpha_characters(tweet):\n",
    "    return ''.join(character for character in tweet if character.isalpha() or character == ' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a stream listener"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATABASE_NAME = 'twitter_inference'\n",
    "TABLE_NAME = 'tweets'\n",
    "USER = 'admindb'\n",
    "HOST = 'localhost'\n",
    "PASSWORD = 'toor'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "from tweepy import StreamListener"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PersistedStreamListener(StreamListener):\n",
    "    def __init__(self):\n",
    "        self._database_connection = psycopg2.connect(dbname=DATABASE_NAME, user=USER, host=HOST, password=PASSWORD)\n",
    "        super().__init__()\n",
    "\n",
    "    def on_status(self, status):\n",
    "        cleaned_status_text = self._clean_status_text(status.text)\n",
    "        self._insert_status(id_str=status.id_str, text = cleaned_status_text)\n",
    "\n",
    "    def _clean_status_text(self, status_text):\n",
    "        cleaned_status_text = status_text\n",
    "        for cleaning_function in self._cleaning_functions:\n",
    "            cleaned_status_text = cleaning_function(cleaned_status_text)\n",
    "        return cleaned_status_text\n",
    "\n",
    "    def _insert_status(self, id_str, text):\n",
    "        cursor = self._database_connection.cursor()\n",
    "        insert_statement = f\"\"\" INSERT INTO {TABLE_NAME} VALUES ( '{id_str}', '{text}' ); \"\"\"\n",
    "        #import pdb; pdb.set_trace()\n",
    "        cursor.execute(insert_statement)\n",
    "        self._database_connection.commit()\n",
    "        cursor.close()\n",
    "    \n",
    "    @property\n",
    "    def _cleaning_functions(self):\n",
    "        return [make_lowercase, remove_diacritics, remove_non_alpha_characters]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "streaming_api = Stream(auth=auth, listener=PersistedStreamListener())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sip from the firehouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "streaming_api.filter(locations=COLOMBIA_GEO_LOCATION_BOUNDING_BOX, is_async=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import beta as beta_distribution\n",
    "\n",
    "X_VALUES = np.linspace(0,1,1002)[1:-1]\n",
    "DATABASE_CONNECTION = psycopg2.connect(dbname=DATABASE_NAME, user=USER, host=HOST, password=PASSWORD)\n",
    "KEYWORD = 'yo'\n",
    "\n",
    "def fetch_tweets(db_conn = DATABASE_CONNECTION):\n",
    "    cursor = db_conn.cursor()\n",
    "    select_statement = f\"\"\"SELECT tweet FROM {TABLE_NAME}\"\"\"\n",
    "    cursor.execute(select_statement)\n",
    "    result = cursor.fetchall()\n",
    "\n",
    "    return [tweet[0] for tweet in result]\n",
    "\n",
    "\n",
    "def compute_alpha_and_beta(tweets, keyword=KEYWORD):\n",
    "    number_of_occurrences = sum(keyword in tweet for tweet in tweets)\n",
    "    alpha = 1 + number_of_occurrences\n",
    "    beta = 1 + (len(tweets)- number_of_occurrences)\n",
    "    \n",
    "    return alpha, beta\n",
    "    \n",
    "\n",
    "def compute_pdf_y_values(alpha, beta, x_values=X_VALUES):\n",
    "    return beta_distribution(alpha, beta).pdf(x_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Requirement already satisfied: nest_asyncio in /home/angelfa/.virtualenvs/datascience_platzi/lib/python3.8/site-packages (1.4.0)\n\u001b[33mWARNING: You are using pip version 20.2.2; however, version 20.2.3 is available.\nYou should consider upgrading via the '/home/angelfa/.virtualenvs/datascience_platzi/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
    }
   ],
   "source": [
    "\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.client import push_session\n",
    "from bokeh.models import FixedTicker\n",
    "from bokeh.plotting import figure, curdoc, reset_output\n",
    "\n",
    "# reset_output\n",
    "reset_output()\n",
    "\n",
    "# initialize alpha, beta\n",
    "tweets = fetch_tweets()\n",
    "alpha, beta = compute_alpha_and_beta(tweets=tweets)\n",
    "pdf_y_values = compute_pdf_y_values(alpha, beta)\n",
    "\n",
    "# create bokeh figure\n",
    "bokeh_figure = figure(\n",
    "    title='PDF of True Probability of a Tweet containing keyword',\n",
    "    x_axis_label='True probability',\n",
    "    y_axis_label='probability_density',\n",
    "    width=1000,\n",
    "    height=600\n",
    ")\n",
    "bokeh_figure.xaxis[0].ticker=FixedTicker(ticks=list(np.linspace(0, 1, 21)))\n",
    "bokeh_line = bokeh_figure.line(X_VALUES, pdf_y_values, color=\"navy\", line_width=4)\n",
    "\n",
    "# open a session to keep out local document in sync with server\n",
    "session = push_session(curdoc())\n",
    "\n",
    "def update():\n",
    "    tweets = fetch_tweets()\n",
    "    alpha, beta = compute_alpha_and_beta(tweets=tweets)\n",
    "    pdf_y_values = compute_pdf_y_values(alpha, beta)\n",
    "    bokeh_line.data_source.data.update(y=pdf_y_values)\n",
    "\n",
    "curdoc().add_periodic_callback(update, 50)\n",
    "\n",
    "session.show(bokeh_figure)\n",
    "session._loop_until_closed()\n",
    "#session.loop_until_closed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "818"
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "source": [
    "len(fetch_tweets())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}